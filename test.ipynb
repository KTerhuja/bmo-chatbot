{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import GooglePalm\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import GooglePalmEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI, AzureChatOpenAI, ChatAnthropic\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.document_loaders import DirectoryLoader,PyPDFLoader\n",
    "# from langchain.document_loaders import UnstructuredExcelLoader\n",
    "# from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain import PromptTemplate\n",
    "# from langchain.vectorstores import Chroma\n",
    "# from langchain.agents.tools import Tool\n",
    "# from langchain.experimental.plan_and_execute import PlanAndExecute, load_agent_executor, load_chat_planner\n",
    "# from langchain import OpenAI, VectorDBQA\n",
    "# from langchain.chains.router import MultiRetrievalQAChain\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "# from langchain.document_loaders import UnstructuredPDFLoader\n",
    "from langchain.callbacks import StdOutCallbackHandler\n",
    "\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_doc(path,pages=[]):\n",
    "    if path.endswith(\".pdf\"):\n",
    "        doc = PyPDFLoader(file_path=path)\n",
    "    else:\n",
    "        doc = DirectoryLoader(path=path,glob=\"**/*.pdf\")\n",
    "    document = doc.load()\n",
    "    if len(pages)!=0:\n",
    "        document = [document[i] for i in pages]\n",
    "    context = \"\\n\\n\".join([document[i].page_content for i in range(len(document))])\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"ANTHROPIC_API_KEY\"] = \"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\"\n",
    "claude_models = [\"claude-instant-1\",\"claude-2\"]\n",
    "anthropic_llm = ChatAnthropic(model=claude_models[1],temperature= 0,max_tokens_to_sample = 512)\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"36ed7c12ee2344d18a3f71ddeb477ce6\"\n",
    "os.environ[\"OPENAI_API_TYPE\"] =\"azure\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] =\"2023-05-15\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://testavinx.openai.azure.com/\"\n",
    "\n",
    "openai_llm = AzureChatOpenAI(deployment_name=\"gpt-35-turbo\",model_name=\"gpt-35-turbo\",temperature=0)\n",
    "embeddings = OpenAIEmbeddings(deployment=\"embedding1\",model=\"text-embedding-ada-002\",openai_api_base=\"https://testavinx.openai.azure.com/\",openai_api_type=\"azure\",chunk_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = {\n",
    "    \"Bank of Montreal Annual Report\":load_doc(\"./data/bmo_ar2022 (2).pdf\",[-2]),\n",
    "    \"Basel Capital Adequacy Reporting (BCAR)\":load_doc(\"./data/BCAR.pdf\",[0,1,2])\n",
    "    }  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_answer(retrival_llm,chat_llm,question,docs):\n",
    "    \n",
    "    retrival_system_template = \"\"\"You are a helpful assistant, You need to extract as much text as you can which is relater or relevant to the answer of the user question from the context provided.\n",
    "Do not answer the question if you don't get any relevant text, . \n",
    "Use the following context for finding out the relevant text, do not use previous knowledge just answer from the context given below:\n",
    "\n",
    "{doc_name}\n",
    "\n",
    "{context}\n",
    "\"\"\"\n",
    "    \n",
    "    retrival_system_prompt = SystemMessagePromptTemplate.from_template(template=retrival_system_template)\n",
    "    messages = [retrival_system_prompt,HumanMessage(content=question)]\n",
    "    compare_chat_prompt = ChatPromptTemplate.from_messages(messages)\n",
    "    \n",
    "    summary = dict()\n",
    "    for doc_name,doc_txt in tqdm(docs.items()):\n",
    "        summary[doc_name] = retrival_llm(compare_chat_prompt.format_prompt(doc_name=doc_name,context=doc_txt).to_messages()).content\n",
    "\n",
    "    compare_context = \"\\n\\n\".join([f\"Relevant points from {doc_name}:\\n\\n{doc_summary}\" for doc_name,doc_summary in summary.items()])\n",
    "    \n",
    "    compare_system_template = \"\"\"You are a helpful chatbot who has to answer question of a user from the institute {institute}.\n",
    "You will be given relevant points from various documents that will help you answer the user question.\n",
    "Below is a list of relevant points along with the name of the document from where thoes points are from.\n",
    "Consider all the documents provided to you and answer the question by choosing all the relevant points to the question.\n",
    "You might have to compare points from more than one document to answer the question.\n",
    "\n",
    "{context}\"\"\"\n",
    "\n",
    "    compare_system_prompt = SystemMessagePromptTemplate.from_template(template=compare_system_template)\n",
    "    messages = [compare_system_prompt,HumanMessage(content=question)]\n",
    "    compare_chat_prompt = ChatPromptTemplate.from_messages(messages)\n",
    "    response = chat_llm(compare_chat_prompt.format_prompt(institute=\"Bank of Montreal (BMO)\",question=question,context=compare_context).to_messages()).content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"According to the Fiscal year end mentioned in the annual report when should BMO file BCAR?\"\n",
    "# question = \"what are schedule bank BMO has to submit for BCAR Credit risk?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.10s/it]\n"
     ]
    }
   ],
   "source": [
    "test = compare_answer(openai_llm,openai_llm,question,docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the relevant points from the Bank of Montreal Annual Report, the Fiscal Year End for Bank of Montreal is October 31. However, there is no information provided regarding the filing of BCAR. But according to the relevant points from Basel Capital Adequacy Reporting (BCAR), institutions with fiscal year-ends of October should file BCAR quarterly in January, April, July, and October. Therefore, BMO should file BCAR quarterly in January, April, July, and October.\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(docs[\"Basel Capital Adequacy Reporting (BCAR)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
